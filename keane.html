<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Recent Works of Mark T. Keane</title>
    <meta charset="utf-8" />
    <meta name="author" content="Layla Bouzoubaa" />
    <script src="libs/header-attrs-2.10/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="assets/ninjutsu.css" type="text/css" />
    <link rel="stylesheet" href="assets/kunoichi.css" type="text/css" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Recent Works of Mark T. Keane
## Foundations &amp; Research in CBR Seminar
### Layla Bouzoubaa
### Last Updated: 2021-08-18

---




# Objectives

- Who is Mark T. Keane?

- Understand foundations of sustainable dairy farming research

- Identify key methods in dairy farming CBR system

- Discuss ICCBR 2021 work on counterfactual explanations


---
class: inverse center middle

# Who is this guy?

![](img/keane.png)

---
class: split-25 white center
layout: false

row.white[
# A Cognitive Scientist
]

.row[
.split-three[
.column[.content[
.center[
## Professor &amp; Chair
]

![](img/bio.png)

.red[*14k (Google Scholar)]
]]

.column[.content[
## Author

![:scale 80%](img/book.jpeg)

]]

.column[.content[
## Grows Garlic

![:scale 80%](img/tweet.png) 

]]

]]

???
Mark Keane is a cognitive computer scientist. HE is Professor and Chair of Computer Science and UCD.14k+ citations (Google Scholar). He an expert in the cognitive sciences - having written several books, like Cognitive Psychology: A Student's Handbook, Advances in the Psychological Thinking. His expertise is also split in the computer sciences - where he focuses on topics like NLP, machine learning, CBR, text analytics and XAI.

---
## Predicting Sickness in Dairy Cows

.pull-left[
- classifier system to predict mastitis in dairy cows

- predict if a cow will become infected or heal within 7 days
  - end-to-end system using stakeholder input
  - reasonings included features that are actionable
  
- data source: 7 dairy farms across Ireland (2010-2019) ~ 2,300 cows

- model: gradient boosting classifier
  - outcome: days until infection
  
- conclusion: even ~70% accuracy would greatly benefit
]

.pull-right[

![](img/illness.png)
]
???
Keane's team gave a workshop talk on this paper at this years AAAI conference.
mastitis = infections in the utter which costs billions in waste 
rationale:farmers find infection to late due to lack of skill thus raising risk in spread/extend length of sickness
system: end-to-end classification system using stakeholder input. reasonings include features that are actionable which increases user acceptance. they also needed to assure that the system performed at an accuracy level acceptable to stakeholders. to do that, they made sure get feedback received from farmers and veterinarians while building the system on specific accuracy measures for classifying a healthy milking vs infectious, how much time is needed to communicate to the farmer that a cow is at risk of infection and which features are actually actionable for the farmers and their confidence levels.
data: contained details on milking procedures(total amount of milk produced each day) as well as mastitis (how and when the cow was infected)

model: gradient boosting classifier with levels being a healthy milking in the next 7 days or an infected milking
conclusion: vet also input that even a 12 hour notice could give a farmer enough time to isolate the sick cow



---
## Break it Down

.pull-left[

- In the CBR context
  - set of analytic tasks - classification
- Propensity model
  - predict likelihood that a cow will develop mastitis in the next 7 days
- Gradient Boosting 
  - training set - data from 2010-2018
  - test set - data from 2018-2019
  - determine which cow belong in each day
- Use of counterfactuals
  - *positive class* = prediction that a cow will be infected
  - use of nearest unlike neighbors
  - *If cow #42 had an increase of one and a half units with respect to Yield she would be likely to succumb to mastitis.*
]

.pull-right[

![](img/features.png)

![](img/probs.png)
]
???
here has been work done on predicting illness in cows however none have been coupled with explanations to allow for more actionable decisions. This paper uses counterfactuals to explain the causal importance of a set of features that are both actionable and confidence building as its been shown that people, psychologically, can more naturally understand the causal roles of a feature had it been different.

After data were collected, a propensity model was developed to predict likelihood that a cow will develop mastitis in the next 7 days. for those that aren't familiar with propensity modeling - propensity modeling is a way to identify who or what in your sample are more likely to make a purchase, receive a certain treatment or in this case get infected. it involves calculating probabilities on a subset of the sample that have been "exposed" or present with a known characteristic to the outcome, given a set of confounding variables, on each patient. the point is to eliminate some of the confounding bias for all observed covariates. 

on GB: a machine learning technique for regression, classification and other tasks, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.

counterfactuals: given the binary classification model- the team aimed to derive the positive class - the prediction that a cow will get infected with explanations. they set a constraint on no more than three features - that are actionable (milk yield) and confidence building (SCC)

Comments:
The methods are a bit unclear - were the propensity scores includes in the model or were the trees split on propensity? 

"pg.68 When these methods can be applied successfully, they are hard to beat." is this a CBR application?
---
### Counterfactual Explanations for Time Series Classification

.pull-left[
- Rationale: predictions made on time series data are opaque in explanations

- Solution: *Native Guide*
  - model-agnostic, case-based technique to generate counterfactuals
  - shows how a time series query could change had the system predicted an alternative class
]

.pull-right[
![](img/counterfactual_paper.png)
]

???

This paper we proposes an explainable case-based reasoning (XCBR) solution to an XAI problem - explaining time series predictions.
---
## Time Series Classification (TSC)

- Examples:
  - healthcare: look at a patient's timeline to detect potential abnormalities
  - food spectroscopy: detect differences between food varietals
- Classification CBR 
  - dynamic problem (vs. static)
- case-base: set of usually linearly ordered time sequences.
  - what is retrieved from a query is a nearest neighbor sequence
- similarity: 
  - Euclidean distances
  - dynamic time warping
  - longest common sub sequence similarity
  - probabilistic methods
  - general transformations


???
before we can delve deeper into native guide, let's talk a little bit about tsc systems.
food: cheaper sensors since only a small portion of time series is used for discrimintative classification

knowledge container: prediction is one of the most common applications of time series
case base contains a set of observed time sequences.
similarity: each measurement of one time series is mapped onto at least one measurement of the other time series and that the mapping preserves the chronological order of the measurements.

DTW: In some time series domains, a very simple distance measure such as the Euclidean
distance will suffice. However, it is often the case that the two sequences have
approximately the same overall component shapes, but these shapes do not line up in Xaxis. 
---
## Good Counterfactuals for TS


.pull-left[

**Generally**

- Causally informative
- Psychologically effective
- Legally compliant with GDPR

**For TS**
- Proximity
  - how close the to-be-explained query is to the generated counterfactual instance
  
- Sparsity
  - counterfactual instances that change fewer features 
  - single portion of the time series
]
.pull-right[

- Plausibility

- Diversity
  - a system should be able to produce multiple diverse explanations for a single query case

&lt;br&gt;
![](img/counterfactual.png)
]

???
Generally, these are the traits of good counterfactual explanations
Keane argues that counterfactual XAI solns for TS are rare and are virtually non-existent for XCBR solns
proximity: how close the to-be-explained query is to the generated counterfactual instance using some of the distance metrics described
sparsity- as stated before, it is preferred to have less than 2 features for explanations on psychological grounds. However due to the multi-dimensionality of time series data, this is not possible. it has been proposed that semantically-meaningful/disciminative information is contained in contiguous subsequence of the series, meaning, a single portion of the time series rather than random points in time
explanations need to plausible as they can be representetive of the underlying data distribution - some suggest that proximity is a good proxy for plausibility
diversity: a system should be able to produce multiple diverse explanations for a single query case. One advantage of this is that different users may find different explanations helpful

img = examples of implausible counterfactuals that are out of distribution even thought they have high proximity

---
## Native Guide

Relies on existing instances in the training data and prioritizes candidate solutions that meet the four key properties
.pull-left[
**Steps**
1. retrieve native guide
  - can guarantee plausibility
2. adapt native guide to generate counterfactual
  - the native guide is perturbed towards the to-be-explained query-case
  - distance between time sequences calculated (DTW)
  - guarantee sparsity
![](img/ts-counter-eqn.png)
]

.pull-right[
![:scale 80%](img/nun.png)
![:scale 80%](img/dtw.png)
]


???
Native Guide relies upon existing instances in the training data, sor nearest unlike neighbors (NUNs), that it retrieves and adapts to generate counterfactual explanations 
Given a query time series, Tq, find a coun- terfactual instance, T ′ , that exists in the case-base. An example of one such instance is the query’s nearest unlike neighbor (T′ ). In using native counterfactual cases we can guarantee plausibility as it is within the distribution.

step2: to produce more proximate explanatory counterfactual, the native guide is perturbed towards the to-be-explained query-case

DTW - basically acceleration/deceleration of signals along the time dimension - used when you have sequences of possibly different lengths

sparsity is guaranteed in that only semantically-meaningful features perturbed. looking at the equation, using the feature-weights, the method seeks to modify contiguous, subsequences, rather than the whole time series, as follows by looking at the equation.
weights for the features can be extracted using different techniques. this process is iterative in that small subsequences are analysed until the optimal counteractual is found. 
This adaptation step improves the proximity and plausibility of the generated coun- terfactuals. then diversity is met since you can extract the next nearest unlikely  neighbor and so forth.
---
## Testing Native Guide: 5 datasets

1. 5 datasets
2. baseline models: *w-counterfactual* &amp; NUN-CF
3. time-series classifier: fully convo- lutional neural network (FCN)  

Probing for Proximity and Sparsity

![:scale 60%](img/prox-test.png)


???
The w-counterfactual method (w-CF) is a key benchmark method; it is the most cited counterfactual XAI method in the literature

The black-box classifier used was a fully convo- lutional neural network (FCN). enabling explicit comparisons to in-sample counterfactual instance. 

Proximity was evaluated using the relative counterfactual distance. Basically, this measure determines whether the dis- tance between the query and the generated counterfactual is closer than that between the query and its “naturally-occurring” NUN. As in some other studies [21], three distance metrics were used; (i) Manhattan Distance (L1 norm), (ii) Euclidean Distance (L2 norm), and (iii) Chebyshev Distance (l∞ norm).

Comparative tests on diverse datasets from the UCR archive using a fully convolutional neural network, demonstrate that the explanatory counterfactuals produced by Native Guide are significantly better than (i) explanations that already existed in the case-base (from NUN-CF) and (ii) ex- planations produced by constraint-based optimisation techniques (from w-CF).
---
## References



- 
&lt;p&gt;&lt;cite&gt;Ryan, C., C. Guéret, D. Berry, et al.
(2021).
&amp;ldquo;Predicting Illness for a Sustainable Dairy Agriculture: Predicting and Explaining the Onset of Mastitis in Dairy Cows&amp;rdquo;.
In: &lt;em&gt;CoRR&lt;/em&gt; abs/2101.02188.
eprint: 2101.02188.
URL: &lt;a href="https://arxiv.org/abs/2101.02188"&gt;https://arxiv.org/abs/2101.02188&lt;/a&gt;.&lt;/cite&gt;&lt;/p&gt;

- Richter M.M., Weber R.O. (2013) Complex Similarity Topics. In: Case-Based Reasoning. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-3-642-40167-1_20

- Delaney, Greene, Keane, (2021) "Instance-based Counterfactual Explanations for Time Series Classification"

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="assets/macros.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
